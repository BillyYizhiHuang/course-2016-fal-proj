{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "document\n",
      "  prefix ont <http://datamechanics.io/ontology#>\n",
      "  prefix bdp <https://data.cityofboston.gov/resource/>\n",
      "  prefix log <http://datamechanics.io/log#>\n",
      "  prefix dat <http://datamechanics.io/data/andradej_chojoe>\n",
      "  prefix alg <http://datamechanics.io/algorithm/andradej_chojoe>\n",
      "  \n",
      "  agent(alg:#bigBelly, [ont:Extension=\"py\", prov:type='prov:SoftwareAgent'])\n",
      "  entity(bdp:nybq-xu5r, [ont:Extension=\"json\", prov:label=\"Big Belly Alerts 2014\", prov:type=\"ont:DataResource\"])\n",
      "  activity(log:uuid849c564f-b278-4906-8de4-185569cc77e1, -, -)\n",
      "  wasAssociatedWith(log:uuid849c564f-b278-4906-8de4-185569cc77e1, alg:#bigBelly, -)\n",
      "  used(log:uuid849c564f-b278-4906-8de4-185569cc77e1, bdp:nybq-xu5r, -, [prov:type=\"ont:Retrieval\"])\n",
      "  entity(dat:#bigbelly, [prov:label=\"Big Belly Locations\", prov:type=\"ont:DataSet\"])\n",
      "  wasAttributedTo(dat:#bigbelly, alg:#bigBelly)\n",
      "  wasGeneratedBy(dat:#bigbelly, log:uuid849c564f-b278-4906-8de4-185569cc77e1, -)\n",
      "  wasDerivedFrom(dat:#bigbelly, bdp:nybq-xu5r, log:uuid849c564f-b278-4906-8de4-185569cc77e1, log:uuid849c564f-b278-4906-8de4-185569cc77e1, log:uuid849c564f-b278-4906-8de4-185569cc77e1)\n",
      "endDocument\n",
      "{\n",
      "    \"agent\": {\n",
      "        \"alg:#bigBelly\": {\n",
      "            \"prov:type\": {\n",
      "                \"type\": \"prov:QUALIFIED_NAME\",\n",
      "                \"$\": \"prov:SoftwareAgent\"\n",
      "            },\n",
      "            \"ont:Extension\": \"py\"\n",
      "        }\n",
      "    },\n",
      "    \"entity\": {\n",
      "        \"bdp:nybq-xu5r\": {\n",
      "            \"prov:label\": \"Big Belly Alerts 2014\",\n",
      "            \"prov:type\": \"ont:DataResource\",\n",
      "            \"ont:Extension\": \"json\"\n",
      "        },\n",
      "        \"dat:#bigbelly\": {\n",
      "            \"prov:label\": \"Big Belly Locations\",\n",
      "            \"prov:type\": \"ont:DataSet\"\n",
      "        }\n",
      "    },\n",
      "    \"wasAttributedTo\": {\n",
      "        \"_:id3\": {\n",
      "            \"prov:agent\": \"alg:#bigBelly\",\n",
      "            \"prov:entity\": \"dat:#bigbelly\"\n",
      "        }\n",
      "    },\n",
      "    \"wasAssociatedWith\": {\n",
      "        \"_:id1\": {\n",
      "            \"prov:activity\": \"log:uuid849c564f-b278-4906-8de4-185569cc77e1\",\n",
      "            \"prov:agent\": \"alg:#bigBelly\"\n",
      "        }\n",
      "    },\n",
      "    \"wasDerivedFrom\": {\n",
      "        \"_:id5\": {\n",
      "            \"prov:activity\": \"log:uuid849c564f-b278-4906-8de4-185569cc77e1\",\n",
      "            \"prov:generation\": \"log:uuid849c564f-b278-4906-8de4-185569cc77e1\",\n",
      "            \"prov:usedEntity\": \"bdp:nybq-xu5r\",\n",
      "            \"prov:usage\": \"log:uuid849c564f-b278-4906-8de4-185569cc77e1\",\n",
      "            \"prov:generatedEntity\": \"dat:#bigbelly\"\n",
      "        }\n",
      "    },\n",
      "    \"prefix\": {\n",
      "        \"ont\": \"http://datamechanics.io/ontology#\",\n",
      "        \"log\": \"http://datamechanics.io/log#\",\n",
      "        \"bdp\": \"https://data.cityofboston.gov/resource/\",\n",
      "        \"dat\": \"http://datamechanics.io/data/andradej_chojoe\",\n",
      "        \"alg\": \"http://datamechanics.io/algorithm/andradej_chojoe\"\n",
      "    },\n",
      "    \"used\": {\n",
      "        \"_:id2\": {\n",
      "            \"prov:activity\": \"log:uuid849c564f-b278-4906-8de4-185569cc77e1\",\n",
      "            \"prov:entity\": \"bdp:nybq-xu5r\",\n",
      "            \"prov:type\": \"ont:Retrieval\"\n",
      "        }\n",
      "    },\n",
      "    \"activity\": {\n",
      "        \"log:uuid849c564f-b278-4906-8de4-185569cc77e1\": {}\n",
      "    },\n",
      "    \"wasGeneratedBy\": {\n",
      "        \"_:id4\": {\n",
      "            \"prov:activity\": \"log:uuid849c564f-b278-4906-8de4-185569cc77e1\",\n",
      "            \"prov:entity\": \"dat:#bigbelly\"\n",
      "        }\n",
      "    }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "import urllib.request\n",
    "import json\n",
    "import dml\n",
    "import prov.model\n",
    "import datetime\n",
    "import uuid\n",
    "import numpy as np\n",
    "import math\n",
    "import sys\n",
    "\n",
    "def project(R, p):\n",
    "    return [p(t) for t in R]\n",
    "\n",
    "def select(R, s):\n",
    "    return [t for t in R if s(t)]\n",
    "\n",
    "# Takes in a key value set and applies function to values of the set.\n",
    "# In this scenario, average fullness percentage is found and the total number of bellies\n",
    "# per zipcode are found\n",
    "# @R: set of key, value pairs\n",
    "# @f: function applied to the value of the pair\n",
    "def aggregate(R, f):\n",
    "    \n",
    "    fullness = []\n",
    "    count = []\n",
    "    results = []\n",
    "    \n",
    "    #keys are all possible unique zip codes\n",
    "    keys = {r[0] for r in R}\n",
    "    \n",
    "    for key in keys:\n",
    "        fullness = [] #reset fullness tracker\n",
    "        count = [] #reset count tracker\n",
    "        for value in R:\n",
    "            if key == value[0]: \n",
    "                fullness.append(value[1])\n",
    "                count.append(value[2])\n",
    "        results.append((key, float(f(fullness)/f(count)), f(count)))\n",
    "    \n",
    "    return results #:D\n",
    "\n",
    "# --------------------------------USED THIS ONE --------------------------------\n",
    "# Processes and projects the current data in the dataset to produce key, value pair\n",
    "# Key: Zipcode\n",
    "# Value: percentage full, count\n",
    "# @dict: gets raw data from city of boston data portal\n",
    "def processData(row):\n",
    "    lat = row['location']['coordinates'][1]\n",
    "    lon = row['location']['coordinates'][0]\n",
    "    percentage = fullnessPercentage(row['fullness'])\n",
    "\n",
    "    #we append the newly contructed tuple format while appending a 1 to each tuple for \n",
    "    #summation purposes later\n",
    "    return (((lat, lon), percentage, 1))\n",
    "\n",
    "# Takes in a string representation of color and returns the associated fullness percentage              \n",
    "# @color: String of color (ex: Red, Yellow, Green)\n",
    "def fullnessPercentage(color):\n",
    "    if color == 'GREEN':\n",
    "        return 0.2\n",
    "    elif color == 'YELLOW':\n",
    "        return 0.6\n",
    "    elif color == 'RED':\n",
    "        return 1.0\n",
    "    else:\n",
    "        return 0\n",
    "    \n",
    "#takes a list and translates its individual elements to dictionaries\n",
    "def dictionarify(R):\n",
    "    result = []\n",
    "    for r in R:\n",
    "        #result.update('zipcode': r[0], 'days': r[1]})\n",
    "        result.append((('location', r[0]), ('percentage', r[1]), ('count', r[2])))\n",
    "    return result\n",
    "\n",
    "# -----------------------Geolocation functions (START - fix)----------------------------------------\n",
    "def retrieveLocations(row):\n",
    "    try:\n",
    "        if row['geocoded_location']['coordinates'] and row['p_zipcode']:\n",
    "            zipcode = row['p_zipcode']\n",
    "            lat = row['geocoded_location']['coordinates'][1]\n",
    "            lon = row['geocoded_location']['coordinates'][0]\n",
    "            coordinates = (lat, lon)\n",
    "            return (zipcode, coordinates)      \n",
    "    except:\n",
    "        return None\n",
    "    return None\n",
    "\n",
    "# does cleanup on the projection to get rid of None values\n",
    "def removeNoneValues(row):\n",
    "    if row:\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "\n",
    "#finds all associated coordinates with a zipcode\n",
    "def aggregateAllCoordinates(R):\n",
    "    #keys are all possible unique zip codes\n",
    "    keys = {r[0] for r in R}\n",
    "    \n",
    "    # contains all associated coordinates\n",
    "    coordinates = []\n",
    "    \n",
    "    # contains the resulting set\n",
    "    result = []\n",
    "    \n",
    "    for key in keys:\n",
    "        coordinates = []\n",
    "        for value in R:\n",
    "            if value[0] == key:\n",
    "                coordinates.append(value[1])\n",
    "        result.append((key, list(set(coordinates))))\n",
    "    return result\n",
    "\n",
    "# returns a centroid for each zipcode - intended to be used as a k means clustering centroid by zipcode\n",
    "def findRegions(row):\n",
    "    x_coor = []\n",
    "    y_coor = []\n",
    "    for coordinate in row[1]:\n",
    "        x_coor.append(coordinate[0])\n",
    "        y_coor.append(coordinate[1])\n",
    "    centroid_x = sum(x_coor) / len(x_coor)\n",
    "    centroid_y = sum(y_coor) / len(y_coor)                   \n",
    "    return (row[0], (centroid_x, centroid_y))\n",
    "\n",
    "# special projection transformation to convert geolocations to zipcode\n",
    "def convert(R, S):\n",
    "    return [convertCoordinatesToZip(r, S) for r in R]\n",
    "\n",
    "def convertCoordinatesToZip(row, zip_coor):\n",
    "    min_dist = float('inf')\n",
    "    zipcode = \"\"\n",
    "    for value in zip_coor:\n",
    "        if euclideanDistance(value[1], row[0]) < min_dist:\n",
    "            min_dist = euclideanDistance(value[1], row[0])\n",
    "            zipcode = value[0]\n",
    "    return (zipcode, row[1], row[2])\n",
    "    \n",
    "def euclideanDistance(coor1,coor2):\n",
    "    return math.sqrt((coor2[0] - coor1[0])**2 + (coor2[1] - coor1[0])**2)\n",
    "# -----------------------Geolocation functions (END - fix)----------------------------------------\n",
    "\n",
    "\n",
    "class bigbelly(dml.Algorithm):\n",
    "    contributor = 'andradej_chojoe'\n",
    "    reads = []\n",
    "    writes = ['andradej_chojoe.bigbelly']\n",
    "\n",
    "# -------------------- Fix this ---------------------------------------------\n",
    "#     #Grabs Master Address List to figure out zipcodes based on Geolocation\n",
    "#     addrCoordinates = \"https://data.cityofboston.gov/resource/je5q-tbjf.json\"\n",
    "#     geoCoordinates = urllib.request.urlopen(addrCoordinates).read().decode(\"utf-8\")\n",
    "#     geoCoordinates = json.dumps(json.loads(geoCoordinates), sort_keys=True, indent=2)\n",
    "#     geoCoordinates = json.loads(geoCoordinates) #converts to list and dict\n",
    "    \n",
    "#     geolocCoor = project(geoCoordinates, retrieveLocations)\n",
    "#     geolocCoor = select(geolocCoor, removeNoneValues)\n",
    "#     geolocCoor = aggregateAllCoordinates(geolocCoor)\n",
    "#     geolocCoor = project(geolocCoor, findRegions)\n",
    "#     print(geolocCoor) #zipcode with centriod coordinate\n",
    "# -------------------- Fix this ---------------------------------------------\n",
    "\n",
    "# -------------------- Fix this --------------------------------------------\n",
    "#     get big belly info from repo\n",
    "#     # use other dataset to get big belly zipcodes\n",
    "#     bigbelly_filtered = convert(bigbelly_filtered, geolocCoor)\n",
    "#     bigbelly_filtered = aggregate(bigbelly_filtered, sum)\n",
    "#     print(bigbelly_filtered)\n",
    "# -------------------- Fix this --------------------------------------------\n",
    "    \n",
    "    @staticmethod\n",
    "    def execute(trial = False):\n",
    "        startTime = datetime.datetime.now()\n",
    "\n",
    "        #Set up database connection\n",
    "        client = dml.pymongo.MongoClient()\n",
    "        repo = client.repo\n",
    "        repo.authenticate('andradej_chojoe', 'andradej_chojoe')\n",
    "        \n",
    "        repo.dropPermanent('andradej_chojoe.bigbelly_transf')\n",
    "        repo.createPermanent('andradej_chojoe.bigbelly_transf')\n",
    "\n",
    "        bigbellyinfo = repo['andradej_chojoe.bigbelly'].find()\n",
    "    \n",
    "        #samples data\n",
    "        #bigbellyinfo = bigbellyinfo[:100]\n",
    "    \n",
    "        # transformations\n",
    "        bigbelly_filtered = project(bigbellyinfo, processData)\n",
    "        bigbelly_filtered = aggregate(bigbelly_filtered, sum)\n",
    "        bigbelly_filtered = dictionarify(bigbelly_filtered)\n",
    "        \n",
    "        \n",
    "        for t in bigbelly_filtered:\n",
    "            t = dict(t)\n",
    "            repo['andradej_chojoe.bigbelly_transf'].insert_one(t)\n",
    "\n",
    "        endTime = datetime.datetime.now()\n",
    "        return{'start':startTime, \"end\":endTime} \n",
    "    \n",
    "    @staticmethod\n",
    "    def provenance(doc = prov.model.ProvDocument(), startTime = None, endTime = None):\n",
    "        \n",
    "        client = dml.pymongo.MongoClient()\n",
    "        repo = client.repo\n",
    "        repo.authenticate('andradej_chojoe', 'andradej_chojoe')\n",
    "\n",
    "        doc = prov.model.ProvDocument()\n",
    "        doc.add_namespace('alg', 'http://datamechanics.io/algorithm/andradej_chojoe') # The scripts in / format.\n",
    "        doc.add_namespace('dat', 'http://datamechanics.io/data/andradej_chojoe') # The data sets in / format.\n",
    "        doc.add_namespace('ont', 'http://datamechanics.io/ontology#')\n",
    "        doc.add_namespace('log', 'http://datamechanics.io/log#') # The event log.\n",
    "        doc.add_namespace('bdp', 'https://data.cityofboston.gov/resource/')\n",
    "        \n",
    "        this_script = doc.agent('alg:#bigBelly', {prov.model.PROV_TYPE:prov.model.PROV['SoftwareAgent'], 'ont:Extension':'py'})\n",
    "        bigbelly_rsc = doc.entity('bdp:nybq-xu5r', {'prov:label':'Big Belly Alerts 2014', \\\n",
    "                                                prov.model.PROV_TYPE:'ont:DataResource', 'ont:Extension':'json'})\n",
    "        run_bigbelly = doc.activity('log:uuid'+str(uuid.uuid4()), startTime, endTime)\n",
    "        doc.wasAssociatedWith(run_bigbelly, this_script)\n",
    "        \n",
    "        doc.usage(run_bigbelly, bigbelly_rsc, startTime, None, \\\n",
    "                  {prov.model.PROV_TYPE:'ont:Retrieval'})\n",
    "        \n",
    "        bigbelly = doc.entity('dat:#bigbelly', {prov.model.PROV_LABEL:'Big Belly Locations', prov.model.PROV_TYPE:'ont:DataSet'})\n",
    "        \n",
    "        doc.wasAttributedTo(bigbelly, this_script)\n",
    "        doc.wasGeneratedBy(bigbelly, run_bigbelly, endTime)\n",
    "        doc.wasDerivedFrom(bigbelly, bigbelly_rsc, run_bigbelly, run_bigbelly, run_bigbelly)\n",
    "        \n",
    "        repo.record(doc.serialize()) # Record the provenance document.\n",
    "        repo.logout()\n",
    "\n",
    "        return doc\n",
    "\n",
    "bigbelly.execute()\n",
    "doc = bigbelly.provenance()\n",
    "print(doc.get_provn())\n",
    "print(json.dumps(json.loads(doc.serialize()), indent=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
