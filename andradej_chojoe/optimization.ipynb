{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "document\n",
      "  prefix dat <http://datamechanics.io/data/andradej_chojoe>\n",
      "  prefix log <http://datamechanics.io/log/>\n",
      "  prefix bdp <https://data.cityofboston.gov/resource/>\n",
      "  prefix alg <http://datamechanics.io/algorithm/andradej_chojoe>\n",
      "  prefix ont <http://datamechanics.io/ontology#>\n",
      "  \n",
      "  agent(alg:#optimization, [ont:Extension=\"py\", prov:type='prov:SoftwareAgent'])\n",
      "  entity(dat:#trashSch_transf, [prov:type=\"ont:DataSet\", prov:label=\"Filtered: Trash Schedules\"])\n",
      "  entity(dat:#bigbelly_transf, [prov:type=\"ont:DataSet\", prov:label=\"Filtered: Big Belly\"])\n",
      "  entity(dat:#codeViol_transf, [prov:type=\"ont:DataSet\", prov:label=\"Filtered: Code Violations\"])\n",
      "  entity(dat:#hotline_transf, [prov:type=\"ont:DataSet\", prov:label=\"Filtered: Service Requests\"])\n",
      "  wasAttributedTo(dat:#trashSch_transf, alg:#optimization)\n",
      "  wasAttributedTo(dat:#bigbelly_transf, alg:#optimization)\n",
      "  wasAttributedTo(dat:#codeViol_transf, alg:#optimization)\n",
      "  wasAttributedTo(dat:#hotline_transf, alg:#optimization)\n",
      "  activity(log:uuid41bbb9fb-1656-476e-a9a8-d4ae53004387, 2016-11-13T15:53:54.524118, 2016-11-13T15:53:55.528872, [prov:label=\"Run execute method\"])\n",
      "  wasAssociatedWith(log:uuid41bbb9fb-1656-476e-a9a8-d4ae53004387, alg:#optimization, -)\n",
      "  entity(dat:#optimization_locations, [prov:type=\"ont:DataSet\", prov:label=\"Optimized Trash Locations\"])\n",
      "  wasAttributedTo(dat:#optimization_locations, alg:#optimization)\n",
      "  wasGeneratedBy(dat:#optimization_locations, log:uuid41bbb9fb-1656-476e-a9a8-d4ae53004387, 2016-11-13T15:53:55.528872)\n",
      "  wasDerivedFrom(dat:#optimization_locations, dat:#trashSch_transf, log:uuid41bbb9fb-1656-476e-a9a8-d4ae53004387, log:uuid41bbb9fb-1656-476e-a9a8-d4ae53004387, log:uuid41bbb9fb-1656-476e-a9a8-d4ae53004387)\n",
      "  wasDerivedFrom(dat:#optimization_locations, dat:#bigbelly_transf, log:uuid41bbb9fb-1656-476e-a9a8-d4ae53004387, log:uuid41bbb9fb-1656-476e-a9a8-d4ae53004387, log:uuid41bbb9fb-1656-476e-a9a8-d4ae53004387)\n",
      "  wasDerivedFrom(dat:#optimization_locations, dat:#codeViol_transf, log:uuid41bbb9fb-1656-476e-a9a8-d4ae53004387, log:uuid41bbb9fb-1656-476e-a9a8-d4ae53004387, log:uuid41bbb9fb-1656-476e-a9a8-d4ae53004387)\n",
      "  wasDerivedFrom(dat:#optimization_locations, dat:#hotline_transf, log:uuid41bbb9fb-1656-476e-a9a8-d4ae53004387, log:uuid41bbb9fb-1656-476e-a9a8-d4ae53004387, log:uuid41bbb9fb-1656-476e-a9a8-d4ae53004387)\n",
      "  used(log:uuid41bbb9fb-1656-476e-a9a8-d4ae53004387, dat:#trashSch_transf, 2016-11-13T15:53:54.524118, [prov:type=\"ont:Dataset\"])\n",
      "  used(log:uuid41bbb9fb-1656-476e-a9a8-d4ae53004387, dat:#bigbelly_transf, 2016-11-13T15:53:54.524118, [prov:type=\"ont:Dataset\"])\n",
      "  used(log:uuid41bbb9fb-1656-476e-a9a8-d4ae53004387, dat:#codeViol_transf, 2016-11-13T15:53:54.524118, [prov:type=\"ont:Dataset\"])\n",
      "  used(log:uuid41bbb9fb-1656-476e-a9a8-d4ae53004387, dat:#hotline_transf, 2016-11-13T15:53:54.524118, [prov:type=\"ont:Dataset\"])\n",
      "endDocument\n",
      "{\n",
      "    \"wasDerivedFrom\": {\n",
      "        \"_:id8\": {\n",
      "            \"prov:usage\": \"log:uuid41bbb9fb-1656-476e-a9a8-d4ae53004387\",\n",
      "            \"prov:usedEntity\": \"dat:#trashSch_transf\",\n",
      "            \"prov:generation\": \"log:uuid41bbb9fb-1656-476e-a9a8-d4ae53004387\",\n",
      "            \"prov:generatedEntity\": \"dat:#optimization_locations\",\n",
      "            \"prov:activity\": \"log:uuid41bbb9fb-1656-476e-a9a8-d4ae53004387\"\n",
      "        },\n",
      "        \"_:id11\": {\n",
      "            \"prov:usage\": \"log:uuid41bbb9fb-1656-476e-a9a8-d4ae53004387\",\n",
      "            \"prov:usedEntity\": \"dat:#hotline_transf\",\n",
      "            \"prov:generation\": \"log:uuid41bbb9fb-1656-476e-a9a8-d4ae53004387\",\n",
      "            \"prov:generatedEntity\": \"dat:#optimization_locations\",\n",
      "            \"prov:activity\": \"log:uuid41bbb9fb-1656-476e-a9a8-d4ae53004387\"\n",
      "        },\n",
      "        \"_:id9\": {\n",
      "            \"prov:usage\": \"log:uuid41bbb9fb-1656-476e-a9a8-d4ae53004387\",\n",
      "            \"prov:usedEntity\": \"dat:#bigbelly_transf\",\n",
      "            \"prov:generation\": \"log:uuid41bbb9fb-1656-476e-a9a8-d4ae53004387\",\n",
      "            \"prov:generatedEntity\": \"dat:#optimization_locations\",\n",
      "            \"prov:activity\": \"log:uuid41bbb9fb-1656-476e-a9a8-d4ae53004387\"\n",
      "        },\n",
      "        \"_:id10\": {\n",
      "            \"prov:usage\": \"log:uuid41bbb9fb-1656-476e-a9a8-d4ae53004387\",\n",
      "            \"prov:usedEntity\": \"dat:#codeViol_transf\",\n",
      "            \"prov:generation\": \"log:uuid41bbb9fb-1656-476e-a9a8-d4ae53004387\",\n",
      "            \"prov:generatedEntity\": \"dat:#optimization_locations\",\n",
      "            \"prov:activity\": \"log:uuid41bbb9fb-1656-476e-a9a8-d4ae53004387\"\n",
      "        }\n",
      "    },\n",
      "    \"agent\": {\n",
      "        \"alg:#optimization\": {\n",
      "            \"prov:type\": {\n",
      "                \"$\": \"prov:SoftwareAgent\",\n",
      "                \"type\": \"prov:QUALIFIED_NAME\"\n",
      "            },\n",
      "            \"ont:Extension\": \"py\"\n",
      "        }\n",
      "    },\n",
      "    \"wasAssociatedWith\": {\n",
      "        \"_:id5\": {\n",
      "            \"prov:agent\": \"alg:#optimization\",\n",
      "            \"prov:activity\": \"log:uuid41bbb9fb-1656-476e-a9a8-d4ae53004387\"\n",
      "        }\n",
      "    },\n",
      "    \"entity\": {\n",
      "        \"dat:#bigbelly_transf\": {\n",
      "            \"prov:type\": \"ont:DataSet\",\n",
      "            \"prov:label\": \"Filtered: Big Belly\"\n",
      "        },\n",
      "        \"dat:#codeViol_transf\": {\n",
      "            \"prov:type\": \"ont:DataSet\",\n",
      "            \"prov:label\": \"Filtered: Code Violations\"\n",
      "        },\n",
      "        \"dat:#trashSch_transf\": {\n",
      "            \"prov:type\": \"ont:DataSet\",\n",
      "            \"prov:label\": \"Filtered: Trash Schedules\"\n",
      "        },\n",
      "        \"dat:#optimization_locations\": {\n",
      "            \"prov:type\": \"ont:DataSet\",\n",
      "            \"prov:label\": \"Optimized Trash Locations\"\n",
      "        },\n",
      "        \"dat:#hotline_transf\": {\n",
      "            \"prov:type\": \"ont:DataSet\",\n",
      "            \"prov:label\": \"Filtered: Service Requests\"\n",
      "        }\n",
      "    },\n",
      "    \"activity\": {\n",
      "        \"log:uuid41bbb9fb-1656-476e-a9a8-d4ae53004387\": {\n",
      "            \"prov:endTime\": \"2016-11-13T15:53:55.528872\",\n",
      "            \"prov:label\": \"Run execute method\",\n",
      "            \"prov:startTime\": \"2016-11-13T15:53:54.524118\"\n",
      "        }\n",
      "    },\n",
      "    \"wasGeneratedBy\": {\n",
      "        \"_:id7\": {\n",
      "            \"prov:time\": \"2016-11-13T15:53:55.528872\",\n",
      "            \"prov:activity\": \"log:uuid41bbb9fb-1656-476e-a9a8-d4ae53004387\",\n",
      "            \"prov:entity\": \"dat:#optimization_locations\"\n",
      "        }\n",
      "    },\n",
      "    \"used\": {\n",
      "        \"_:id13\": {\n",
      "            \"prov:type\": \"ont:Dataset\",\n",
      "            \"prov:time\": \"2016-11-13T15:53:54.524118\",\n",
      "            \"prov:activity\": \"log:uuid41bbb9fb-1656-476e-a9a8-d4ae53004387\",\n",
      "            \"prov:entity\": \"dat:#bigbelly_transf\"\n",
      "        },\n",
      "        \"_:id14\": {\n",
      "            \"prov:type\": \"ont:Dataset\",\n",
      "            \"prov:time\": \"2016-11-13T15:53:54.524118\",\n",
      "            \"prov:activity\": \"log:uuid41bbb9fb-1656-476e-a9a8-d4ae53004387\",\n",
      "            \"prov:entity\": \"dat:#codeViol_transf\"\n",
      "        },\n",
      "        \"_:id12\": {\n",
      "            \"prov:type\": \"ont:Dataset\",\n",
      "            \"prov:time\": \"2016-11-13T15:53:54.524118\",\n",
      "            \"prov:activity\": \"log:uuid41bbb9fb-1656-476e-a9a8-d4ae53004387\",\n",
      "            \"prov:entity\": \"dat:#trashSch_transf\"\n",
      "        },\n",
      "        \"_:id15\": {\n",
      "            \"prov:type\": \"ont:Dataset\",\n",
      "            \"prov:time\": \"2016-11-13T15:53:54.524118\",\n",
      "            \"prov:activity\": \"log:uuid41bbb9fb-1656-476e-a9a8-d4ae53004387\",\n",
      "            \"prov:entity\": \"dat:#hotline_transf\"\n",
      "        }\n",
      "    },\n",
      "    \"wasAttributedTo\": {\n",
      "        \"_:id3\": {\n",
      "            \"prov:agent\": \"alg:#optimization\",\n",
      "            \"prov:entity\": \"dat:#codeViol_transf\"\n",
      "        },\n",
      "        \"_:id1\": {\n",
      "            \"prov:agent\": \"alg:#optimization\",\n",
      "            \"prov:entity\": \"dat:#trashSch_transf\"\n",
      "        },\n",
      "        \"_:id6\": {\n",
      "            \"prov:agent\": \"alg:#optimization\",\n",
      "            \"prov:entity\": \"dat:#optimization_locations\"\n",
      "        },\n",
      "        \"_:id2\": {\n",
      "            \"prov:agent\": \"alg:#optimization\",\n",
      "            \"prov:entity\": \"dat:#bigbelly_transf\"\n",
      "        },\n",
      "        \"_:id4\": {\n",
      "            \"prov:agent\": \"alg:#optimization\",\n",
      "            \"prov:entity\": \"dat:#hotline_transf\"\n",
      "        }\n",
      "    },\n",
      "    \"prefix\": {\n",
      "        \"dat\": \"http://datamechanics.io/data/andradej_chojoe\",\n",
      "        \"log\": \"http://datamechanics.io/log/\",\n",
      "        \"bdp\": \"https://data.cityofboston.gov/resource/\",\n",
      "        \"alg\": \"http://datamechanics.io/algorithm/andradej_chojoe\",\n",
      "        \"ont\": \"http://datamechanics.io/ontology#\"\n",
      "    }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "#%matplotlib inline\n",
    "#import matplotlib.pyplot as plt\n",
    "import random\n",
    "from scipy.spatial import cKDTree\n",
    "import math\n",
    "import numpy\n",
    "import urllib.request\n",
    "import json\n",
    "import dml\n",
    "import prov.model\n",
    "import datetime\n",
    "import uuid\n",
    "\n",
    "# to be used in the scatter plot\n",
    "COLORMAP = {'Big Belly': 'g', 'Violations': 'r', 'Requests': 'b', 'Trash Pick-up': 'm'}\n",
    "\n",
    "def project(R, p, dataType):\n",
    "    return [p(t, dataType) for t in R]\n",
    "\n",
    "def difference(R, S):\n",
    "    return [t for t in R if t not in S]\n",
    "\n",
    "def removeCoordinates(R, S):\n",
    "    filtered_list = []\n",
    "    match_found = False\n",
    "    for r in R:\n",
    "        for s in S:\n",
    "            if (r[0], r[1]) == (s[0],s[1]):\n",
    "                match_found = True\n",
    "                break\n",
    "        if not match_found: filtered_list.append(r)\n",
    "        match_found = False\n",
    "    return filtered_list\n",
    "                \n",
    "\n",
    "#returns weights based on average big belly fullness\n",
    "def bbWeights(t):\n",
    "    perc = t['percentage']\n",
    "    if perc >= 0.9 and perc <= 1.0:\n",
    "        return (0.3 * perc)\n",
    "    elif perc >= 0.7 and perc < 0.9:\n",
    "        return (0.25 * perc)\n",
    "    elif perc >= 0.5 and perc < 0.7:\n",
    "        return (0.2 * perc)\n",
    "    elif perc >= 0.3 and perc < 0.5:\n",
    "        return (0.15 * perc)\n",
    "    elif perc >= 0.0 and perc < 0.3:\n",
    "        return (0.1 * perc)\n",
    "    else:\n",
    "        raise ValueError\n",
    "\n",
    "#returns weights based on severity of sanitary violation\n",
    "def violWeights(t):\n",
    "    v = t['type']\n",
    "    count = t['count']\n",
    "    if v == 'improper storage trash':\n",
    "        return (0.75 * count)\n",
    "    elif v == 'illegal dumping':\n",
    "        return (0.75 * count)\n",
    "    elif v == 'overfilling of barrel/dumpster':\n",
    "        return (1.0 * count)\n",
    "    elif v == 'storage of garbage & rubbish':\n",
    "        return (0.75 * count)\n",
    "    #NOTE: labels are double-sapced for Insects Rodents Animals\n",
    "    elif v == 'Insects  Rodents  Animals': \n",
    "        return (0.3 * count)\n",
    "    elif v == 'trash illegally dump container':\n",
    "        return (0.75 * count)\n",
    "    else:\n",
    "        raise ValueError\n",
    "\n",
    "#returns weights based on severity of service request      \n",
    "def reqWeights(t):\n",
    "    v = t['type'].lower()\n",
    "    count = t['count']\n",
    "    if v == 'illegal dumping':\n",
    "        return (0.75 * count)\n",
    "    elif v == 'improper storage of trash (barrels)':\n",
    "        return (0.75 * count)\n",
    "    elif v == 'mice infestation - residential':\n",
    "        return (0.3 * count)\n",
    "    elif v == 'missed trash/recycling/yard waste/bulk item':\n",
    "        return (0.5 * count)\n",
    "    elif v == 'overflowing or un-kept dumpster':\n",
    "        return (1.0 * count)\n",
    "    elif v == 'pest infestation - residential':\n",
    "        return (0.3 * count)\n",
    "    elif v == 'rodent activity':\n",
    "        return (0.5 * count)\n",
    "    elif v == 'unsanitary conditions - establishment':\n",
    "        return (0.3 * count)\n",
    "    else:\n",
    "        raise ValueError\n",
    "\n",
    "#returns negative weights based on the total times trash collected\n",
    "def scheduleWeights(t):\n",
    "    return -1 * t['count']\n",
    "\n",
    "# used to format the data to prepare to graph\n",
    "def process(R, dataType):\n",
    "    color = COLORMAP[dataType]\n",
    "    X = []\n",
    "    Y = []\n",
    "    W = []\n",
    "    for t in R:\n",
    "        lat = float(t['location'][0])\n",
    "        lon = float(t['location'][1])\n",
    "        #weight = int(t['count'])\n",
    "        X.append(lat)\n",
    "        Y.append(lon)\n",
    "        #call helper function and append corresponding weight\n",
    "        if dataType == \"Big Belly\":\n",
    "            scaledW = bbWeights(t)\n",
    "        elif dataType == 'Violations':\n",
    "            scaledW = violWeights(t)\n",
    "        elif dataType == 'Requests':\n",
    "            scaledW = reqWeights(t)\n",
    "        elif dataType == 'Trash Pick-up':\n",
    "            scaledW = scheduleWeights(t)\n",
    "        else:\n",
    "            raise ValueError \n",
    "        W.append(20 * scaledW)\n",
    "#     plt.scatter(X, Y, c=color, alpha=0.5, label=dataType)\n",
    "    return list(zip(X,Y)),list(zip(X,Y,W))\n",
    "\n",
    "def findOptimalLocation(coordinates, weight_list, num_trash, radius = 0.0013, iterations = 15000):\n",
    "    \n",
    "    # keep track of visited coordinates\n",
    "    visited = []\n",
    "    \n",
    "    # final lists to return\n",
    "    trashLocations = []\n",
    "    location_weights = []\n",
    "    \n",
    "    # start the for loop here\n",
    "    for i in range(num_trash):\n",
    "        \n",
    "        #make min weight\n",
    "        max_weight = -float('Inf')\n",
    "        trash_loc = (0,0)\n",
    "        neighbors = []\n",
    "\n",
    "        #make the kd tree\n",
    "        tree = cKDTree(coordinates)\n",
    "\n",
    "        # start the for loop\n",
    "        for i in range(iterations):\n",
    "            # pick a coordinate\n",
    "            random_index = random.randint(0,len(coordinates)-1)\n",
    "            random_coor = coordinates[random_index]\n",
    "    #         print(random_coor)\n",
    "\n",
    "            within_radius = []\n",
    "\n",
    "            distances, indices = tree.query(random_coor, len(coordinates)-1, p=2, distance_upper_bound=radius)\n",
    "            for dist, ind in zip(distances, indices):\n",
    "                # had to typecast inf for float to test to inf\n",
    "                if dist == float('Inf'):\n",
    "                    break\n",
    "                within_radius.append(weight_list[ind])\n",
    "\n",
    "            # if weight is greater than curr max assign new max and new coor\n",
    "            total_weight = sum([r[2] for r in within_radius])\n",
    "            if total_weight > max_weight:\n",
    "                max_weight = total_weight\n",
    "                trash_loc = random_coor\n",
    "                neighbors = within_radius\n",
    "    \n",
    "        # save the found optimization\n",
    "        trashLocations.append(trash_loc)\n",
    "        location_weights.append(200 + (math.pi * radius**2))\n",
    "        \n",
    "        # reset the list to remove already included points        \n",
    "        coordinates = removeCoordinates(coordinates, neighbors)\n",
    "        weight_list = difference(weight_list, neighbors)\n",
    "        \n",
    "#         print(len(weight_list))    \n",
    "#         print(len(coordinates))\n",
    "        \n",
    "    return trashLocations, location_weights\n",
    "    \n",
    "    \n",
    "\n",
    "class optimization(dml.Algorithm):\n",
    "    contributor = 'andradej_chojoe'\n",
    "    reads = ['andradej_chojoe.trashSch_transf', \\\n",
    "             'andradej_chojoe.bigbelly_transf', \\\n",
    "             'andrade_chojoe.codeViolations', \\\n",
    "             'andradej_chojoe.hotline_transf']\n",
    "    writes = ['andradej_chojoe.optimization_results']\n",
    "    \n",
    "    \n",
    "    @staticmethod\n",
    "    def execute(trial = False):\n",
    "        startTime = datetime.datetime.now()\n",
    "\n",
    "        #Set up database connection\n",
    "        client = dml.pymongo.MongoClient()\n",
    "        repo = client.repo\n",
    "        repo.authenticate('andradej_chojoe', 'andradej_chojoe')\n",
    "        \n",
    "        repo.dropPermanent('andradej_chojoe.optimization_results')\n",
    "        repo.createPermanent('andradej_chojoe.optimization_results')\n",
    "        \n",
    "        # gather all the datasets\n",
    "        trashSchData = repo['andradej_chojoe.trashSch_transf'].find()\n",
    "        bigBellyData = repo['andradej_chojoe.bigbelly_transf'].find()\n",
    "        codeViolData = repo['andradej_chojoe.codeViol_transf'].find()\n",
    "        hotlineData = repo['andradej_chojoe.hotline_transf'].find()\n",
    "        \n",
    "        # define the figure\n",
    "#         fig = plt.figure(figsize=(11,8))\n",
    "        \n",
    "        coorBB, bigBellyData = process(bigBellyData, 'Big Belly')\n",
    "        coorCV, codeViolData = process(codeViolData, 'Violations')\n",
    "        coorRQ, hotlineData = process(hotlineData, 'Requests')\n",
    "        coorTS, trashSchData = process(trashSchData, 'Trash Pick-up')\n",
    "        \n",
    "        if trial:\n",
    "            coorBB = coorBB[:500] \n",
    "            bigBellyData = bigBellyData[:500]\n",
    "            coorCV = coorCV[:500]\n",
    "            codeViolData = codeViolData[:500]\n",
    "            coorRQ = coorRQ[:500]\n",
    "            hotlineData = hotlineData[:500]\n",
    "            coorTS = coorTS[:500]\n",
    "            trashSchData = trashSchData[:500]\n",
    "        \n",
    "        # merge all data for master coordinate list (ADD THIS)\n",
    "        masterCoordinateList = coorBB + coorCV + coorRQ + coorTS\n",
    "        masterCoorWeightList = bigBellyData + codeViolData + hotlineData + trashSchData\n",
    "#         print(len(masterCoordinateList))\n",
    "        \n",
    "        # call the optimization function\n",
    "        if trial:\n",
    "            loc,weight = findOptimalLocation(masterCoordinateList, masterCoorWeightList, 5, iterations=2000)\n",
    "        else:\n",
    "            loc, weight = findOptimalLocation(masterCoordinateList, masterCoorWeightList, 5)\n",
    "        \n",
    "#         for coor in loc:\n",
    "#             plt.scatter(coor[0],coor[1],s=weight[0], c='y', alpha=1, label=\"Trash\")\n",
    "        \n",
    "#         # show the graph and make it look nice\n",
    "# #-------------------------------------------------------------------------------------------\n",
    "#         plt.legend(bbox_to_anchor=(0., 1.02, 1., .102), loc=3,\n",
    "#            ncol=2, mode=\"expand\", borderaxespad=0.)\n",
    "#         plt.show()\n",
    "        \n",
    "        #insert into mongo db\n",
    "        for i in range(len(loc)):\n",
    "            entry = {'location': loc[i], 'weight': weight[i]}\n",
    "            repo['andradej_chojoe.optimization_results'].insert_one(entry)\n",
    "            \n",
    "        endTime = datetime.datetime.now()\n",
    "        return{'start':startTime, \"end\":endTime}\n",
    "        \n",
    "    \n",
    "    @staticmethod\n",
    "    def provenance(doc = prov.model.ProvDocument(), startTime = None, endTime = None):\n",
    "        # Set up the database connection.\n",
    "        client = dml.pymongo.MongoClient()\n",
    "        repo = client.repo\n",
    "        repo.authenticate('andradej_chojoe', 'andradej_chojoe')\n",
    "        \n",
    "        doc.add_namespace('alg', 'http://datamechanics.io/algorithm/andradej_chojoe') # The scripts are in <folder>#<filename> format.\n",
    "        doc.add_namespace('dat', 'http://datamechanics.io/data/andradej_chojoe') # The data sets are in <user>#<collection> format.\n",
    "        doc.add_namespace('ont', 'http://datamechanics.io/ontology#') # 'Extension', 'DataResource', 'DataSet', 'Retrieval', 'Query', or 'Computation'.\n",
    "        doc.add_namespace('log', 'http://datamechanics.io/log/') # The event log.\n",
    "        doc.add_namespace('bdp', 'https://data.cityofboston.gov/resource/')\n",
    "        \n",
    "        # define the agent which is the script\n",
    "        this_script = doc.agent('alg:#optimization', {prov.model.PROV_TYPE:prov.model.PROV['SoftwareAgent'], 'ont:Extension':'py'})\n",
    "\n",
    "        # define all entities and all associated arrows from them\n",
    "        trashSch_transf = doc.entity('dat:#trashSch_transf', {'prov:label':'Filtered: Trash Schedules', prov.model.PROV_TYPE:'ont:DataSet'})\n",
    "        bigbelly_transf = doc.entity('dat:#bigbelly_transf', {'prov:label':'Filtered: Big Belly', prov.model.PROV_TYPE:'ont:DataSet'})\n",
    "        codeViol_transf = doc.entity('dat:#codeViol_transf', {'prov:label':'Filtered: Code Violations', prov.model.PROV_TYPE:'ont:DataSet'})\n",
    "        hotline_transf = doc.entity('dat:#hotline_transf', {'prov:label':'Filtered: Service Requests', prov.model.PROV_TYPE:'ont:DataSet'})\n",
    "        doc.wasAttributedTo(trashSch_transf, this_script)\n",
    "        doc.wasAttributedTo(bigbelly_transf, this_script)\n",
    "        doc.wasAttributedTo(codeViol_transf, this_script)\n",
    "        doc.wasAttributedTo(hotline_transf, this_script)\n",
    "        \n",
    "        #define the activity\n",
    "        run_algorithm = doc.activity('log:uuid'+str(uuid.uuid4()), startTime, endTime, {'prov:label':'Run execute method'})\n",
    "        doc.wasAssociatedWith(run_algorithm, this_script)\n",
    "\n",
    "        #define new optimization dataset\n",
    "        optimization_locations = doc.entity('dat:#optimization_locations', {'prov:label':'Optimized Trash Locations', prov.model.PROV_TYPE:'ont:DataSet'})\n",
    "        doc.wasAttributedTo(optimization_locations, this_script)\n",
    "        doc.wasGeneratedBy(optimization_locations, run_algorithm, endTime)\n",
    "        doc.wasDerivedFrom(optimization_locations, trashSch_transf, run_algorithm, run_algorithm, run_algorithm)\n",
    "        doc.wasDerivedFrom(optimization_locations, bigbelly_transf, run_algorithm, run_algorithm, run_algorithm)\n",
    "        doc.wasDerivedFrom(optimization_locations, codeViol_transf, run_algorithm, run_algorithm, run_algorithm)\n",
    "        doc.wasDerivedFrom(optimization_locations, hotline_transf, run_algorithm, run_algorithm, run_algorithm)\n",
    "\n",
    "        # define the usage activities\n",
    "        doc.usage(\n",
    "            run_algorithm,\n",
    "            trashSch_transf,\n",
    "            startTime,\n",
    "            None,\n",
    "            {prov.model.PROV_TYPE:'ont:Dataset'}\n",
    "        )\n",
    "        doc.usage(\n",
    "            run_algorithm,\n",
    "            bigbelly_transf,\n",
    "            startTime,\n",
    "            None,\n",
    "            {prov.model.PROV_TYPE:'ont:Dataset'}\n",
    "        )\n",
    "        doc.usage(\n",
    "            run_algorithm,\n",
    "            codeViol_transf,\n",
    "            startTime,\n",
    "            None,\n",
    "            {prov.model.PROV_TYPE:'ont:Dataset'}\n",
    "        )\n",
    "        doc.usage(\n",
    "            run_algorithm,\n",
    "            hotline_transf,\n",
    "            startTime,\n",
    "            None,\n",
    "            {prov.model.PROV_TYPE:'ont:Dataset'}\n",
    "        )\n",
    "        \n",
    "        # record the prov document\n",
    "        repo.record(doc.serialize()) # Record the provenance document.\n",
    "        repo.logout()\n",
    "        \n",
    "        return doc\n",
    "    \n",
    "times = optimization.execute(trial = True)\n",
    "doc = optimization.provenance(startTime = times['start'], endTime = times['end'])\n",
    "print(doc.get_provn())\n",
    "print(json.dumps(json.loads(doc.serialize()), indent=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
